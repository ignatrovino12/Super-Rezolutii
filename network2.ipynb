{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aefa8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor \n",
    "from torchvision.transforms import Compose, RandomHorizontalFlip, RandomVerticalFlip, RandomRotation, ColorJitter, ToTensor\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x + residual\n",
    "\n",
    "class SRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRNN, self).__init__()\n",
    "        self.input_conv = nn.Conv2d(3, 64, kernel_size=9, padding=4)\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(64) for _ in range(5)]\n",
    "        )\n",
    "        self.channel_reduction = nn.Conv2d(64, 16, kernel_size=3, padding=1)\n",
    "        self.upsample = nn.PixelShuffle(upscale_factor=2)\n",
    "        self.output_conv = nn.Conv2d(4, 3, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.input_conv(x))\n",
    "        x = self.residual_blocks(x)\n",
    "        x = self.relu(self.channel_reduction(x))\n",
    "        x = self.upsample(x)\n",
    "        x = self.output_conv(x)\n",
    "        return x\n",
    "    \n",
    "def preprocess(img_path, scale=2, augment=False):\n",
    "    hr = Image.open(img_path).convert('RGB')\n",
    "    w, h = hr.size\n",
    "    lr = hr.resize((w // scale, h // scale), Image.BICUBIC)\n",
    "\n",
    "    if augment:\n",
    "        augmentation = Compose([\n",
    "            RandomHorizontalFlip(p=0.5),\n",
    "            RandomVerticalFlip(p=0.5),\n",
    "            RandomRotation(degrees=25),\n",
    "            ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
    "        ])\n",
    "        hr = augmentation(hr)\n",
    "        lr = augmentation(lr)\n",
    "\n",
    "    return ToTensor()(lr).unsqueeze(0), ToTensor()(hr).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "def calculate_psnr(output, target, max_pixel_value=1.0):\n",
    "    mse = torch.mean((output - target) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * math.log10(max_pixel_value ** 2 / mse.item())\n",
    "    return psnr\n",
    "\n",
    "model = SRNN()\n",
    "# model.load_state_dict(torch.load('srnn_model.pth'))\n",
    "# model.eval()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "input_img, target_img = preprocess('dataset/train/1.jpg', augment=True)\n",
    "val_input, val_target = preprocess('dataset/validation/2.jpg', augment=False)\n",
    "\n",
    "# update learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "# Antrenare\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_img)\n",
    "    loss = criterion(output, target_img)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step() \n",
    "\n",
    "    # PSNR\n",
    "    train_psnr = calculate_psnr(output, target_img)\n",
    "    \n",
    "    # Validare\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model(val_input)\n",
    "        val_psnr = calculate_psnr(val_output, val_target)\n",
    "    \n",
    "    # Rezultate\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Train PSNR: {train_psnr:.2f} dB, Val PSNR: {val_psnr:.2f} dB\")\n",
    "\n",
    "# Salvez modelul antrenat\n",
    "torch.save(model.state_dict(), 'srnn_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228ed361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to after.jpg\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import  ToPILImage\n",
    "\n",
    "def test_model(model_path, test_img_path, output_path):\n",
    "\n",
    "    model = SRNN()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    input_img, target_img = preprocess(test_img_path,scale=2)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_img)\n",
    "\n",
    "    output_img = ToPILImage()(output.squeeze(0))\n",
    "\n",
    "    input_img = ToPILImage()(input_img.squeeze(0))\n",
    "    input_img.save(\"before.jpg\")\n",
    "\n",
    "    output_img.save(output_path)\n",
    "    print(f\"Output saved to {output_path}\")\n",
    "\n",
    "test_model(\n",
    "    model_path='models2/srnn_model2_scale2.pth', \n",
    "    test_img_path='dataset/test/b.jpg', \n",
    "    output_path='after.jpg'     \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
