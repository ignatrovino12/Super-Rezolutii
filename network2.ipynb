{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86da09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor \n",
    "from torchvision.transforms import Compose,RandomApply,GaussianBlur, RandomHorizontalFlip, RandomVerticalFlip, RandomRotation, ColorJitter, ToTensor\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout2d(p=0.3) \n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x) \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        return x + residual\n",
    "\n",
    "class SRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRNN, self).__init__()\n",
    "        self.input_conv = nn.Conv2d(3, 32, kernel_size=9, padding=4)\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(32) for _ in range(5)]\n",
    "        )\n",
    "        self.channel_reduction = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bicubic', align_corners=False),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_conv = nn.Conv2d(16, 3, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_input = F.interpolate(x, scale_factor=2, mode='bicubic', align_corners=False)\n",
    "        x = self.relu(self.input_conv(x))\n",
    "        x = self.residual_blocks(x)\n",
    "        x = self.relu(self.channel_reduction(x))\n",
    "        x = self.upsample(x)\n",
    "        x = self.output_conv(x)\n",
    "        return x + x_input\n",
    "    \n",
    "\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, img_path, crop_size=64, scale=2, transform=None):\n",
    "        self.hr_image = Image.open(img_path).convert('RGB')\n",
    "        self.crop_size = crop_size\n",
    "        self.scale = scale\n",
    "        self.transform = transform or Compose([\n",
    "            RandomHorizontalFlip(),\n",
    "            RandomVerticalFlip(),\n",
    "            RandomRotation(degrees=90),\n",
    "            ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.3),\n",
    "            RandomApply([GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))], p=0.1),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return 3000  \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        width, height = self.hr_image.size\n",
    "        scaled_crop = self.crop_size * self.scale\n",
    "\n",
    "        left = random.randint(0, width - scaled_crop)\n",
    "        top = random.randint(0, height - scaled_crop)\n",
    "        hr_crop = self.hr_image.crop((left, top, left + scaled_crop, top + scaled_crop))\n",
    "        hr_crop = self.transform(hr_crop)\n",
    "\n",
    "        lr_crop = hr_crop.resize((self.crop_size, self.crop_size), Image.BICUBIC)\n",
    "\n",
    "        return ToTensor()(lr_crop), ToTensor()(hr_crop)\n",
    "\n",
    "def calculate_psnr(output, target, max_pixel_value=1.0):\n",
    "    mse = torch.mean((output - target) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * math.log10(max_pixel_value ** 2 / mse.item())\n",
    "    return psnr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67247875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRNN().to(device)\n",
    "# state_dict = torch.load('/kaggle/input/model5/pytorch/default/1/best_srnn_model (6).pth', weights_only=True)\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.eval()\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "\n",
    "train_dataset = SRDataset('/kaggle/input/sr-dataset/dataset/train/1.jpg', crop_size=64)\n",
    "val_dataset = SRDataset('/kaggle/input/sr-dataset/dataset/validation/2.jpg', crop_size=64)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "best_psnr = 0.0\n",
    "\n",
    "# Antrenare\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_psnr = 0.0\n",
    "\n",
    "    for lr, hr in train_loader:\n",
    "        lr, hr = lr.to(device), hr.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        sr = model(lr)\n",
    "        loss = criterion(sr, hr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * lr.size(0)\n",
    "        total_psnr += calculate_psnr(sr, hr) * lr.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    avg_psnr = total_psnr / len(train_loader.dataset)\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validare\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_psnr = 0.0\n",
    "    with torch.no_grad():\n",
    "        for lr, hr in val_loader:\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "            sr = model(lr)\n",
    "            loss = criterion(sr, hr)\n",
    "            val_loss += loss.item() * lr.size(0)\n",
    "            val_psnr += calculate_psnr(sr, hr) * lr.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_psnr /= len(val_loader.dataset)\n",
    "\n",
    "    if val_psnr > best_psnr:\n",
    "        best_psnr = val_psnr\n",
    "        torch.save(model.state_dict(), 'best_srnn_model.pth')\n",
    "        print(f\"[Epoch {epoch+1}] Model salvat (Val PSNR: {val_psnr:.2f} dB)\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1:03d} | Loss: {avg_loss:.4f} | Train PSNR: {avg_psnr:.2f} dB | Val PSNR: {val_psnr:.2f} dB\")\n",
    "\n",
    "torch.save(model.state_dict(), 'srnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28467c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output salvat în: scale2/after.jpg\n",
      "PSNR pe imaginea completa: 38.30 dB\n",
      "Loss pe imaginea completa: 0.0055\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import os\n",
    "\n",
    "def calculate_psnr(output, target, max_pixel_value=1.0):\n",
    "    mse = torch.mean((output - target) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * math.log10(max_pixel_value ** 2 / mse.item())\n",
    "    return psnr\n",
    "\n",
    "def preprocess_full_image(img_path, scale=2):\n",
    "    hr = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    w, h = hr.size\n",
    "    w -= w % scale\n",
    "    h -= h % scale\n",
    "    hr = hr.crop((0, 0, w, h))\n",
    "\n",
    "    lr = hr.resize((w // scale, h // scale), Image.BICUBIC)\n",
    "    return ToTensor()(lr).unsqueeze(0), ToTensor()(hr).unsqueeze(0)\n",
    "\n",
    "\n",
    "def test_model_full_image(model_path, test_img_path, output_path, scale=2):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = SRNN().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    input_img, target_img = preprocess_full_image(test_img_path, scale=scale)\n",
    "    input_img = input_img.to(device)\n",
    "    target_img = target_img.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_img)\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "    psnr = calculate_psnr(output, target_img)\n",
    "    loss = criterion(output, target_img).item()\n",
    "\n",
    "    to_pil = ToPILImage()\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    to_pil(input_img.squeeze(0).cpu()).save(\"scale2/before.jpg\")\n",
    "    to_pil(output.squeeze(0).cpu()).save(output_path)\n",
    "    to_pil(target_img.squeeze(0).cpu()).save(\"scale2/ground_truth.jpg\")\n",
    "\n",
    "    print(f\"Output salvat în: {output_path}\")\n",
    "    print(f\"PSNR pe imaginea completa: {psnr:.2f} dB\")\n",
    "    print(f\"Loss pe imaginea completa: {loss:.4f}\")\n",
    "\n",
    "test_model_full_image(\n",
    "    model_path='models2/model5.pth',\n",
    "    test_img_path='dataset/validation/2.jpg',\n",
    "    output_path='scale2/after.jpg',\n",
    "    scale=2\n",
    ")\n",
    "\n",
    "# Downsampled by 2x -> PSNR: 38.07 dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ddf5477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR pe imaginea completa: 38.31 dB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_psnr(output, target, max_pixel_value=255.0):\n",
    "    mse = np.mean((output - target) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * np.log10((max_pixel_value ** 2) / mse)\n",
    "    return psnr\n",
    "\n",
    "def preprocess_full_image(img_path, scale=2):\n",
    "    hr = Image.open(img_path).convert('RGB')\n",
    "    w, h = hr.size\n",
    "    w -= w % scale\n",
    "    h -= h % scale\n",
    "    hr = hr.crop((0, 0, w, h))\n",
    "    lr = hr.resize((w // scale, h // scale), Image.BICUBIC)\n",
    "   \n",
    "    lr_np = np.array(lr).astype(np.float32)\n",
    "    hr_np = np.array(hr).astype(np.float32)\n",
    "    return lr_np, hr_np\n",
    "\n",
    "\n",
    "def test_model_full_image(model_path, test_img_path, output_path, scale=2):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SRNN().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    lr_np, hr_np = preprocess_full_image(test_img_path, scale=scale)\n",
    "\n",
    "    input_img = torch.from_numpy(lr_np.transpose(2, 0, 1)).unsqueeze(0).float() / 255.0\n",
    "    input_img = input_img.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_img)\n",
    "\n",
    "    output_np = output.squeeze(0).cpu().numpy().transpose(1, 2, 0) * 255.0\n",
    "    output_np = np.clip(output_np, 0, 255)\n",
    "\n",
    "    psnr = calculate_psnr(output_np, hr_np)\n",
    "    print(f\"PSNR pe imaginea completa: {psnr:.2f} dB\")\n",
    "\n",
    "    Image.fromarray(np.uint8(output_np)).save(output_path)\n",
    "    Image.fromarray(np.uint8(lr_np)).save(\"scale2/before.jpg\")\n",
    "    Image.fromarray(np.uint8(hr_np)).save(\"scale2/ground_truth.jpg\")\n",
    "\n",
    "test_model_full_image(\n",
    "    model_path='models2/model5.pth',\n",
    "    test_img_path='dataset/validation/2.jpg',\n",
    "    output_path='scale2/after.jpg',\n",
    "    scale=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e1f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output salvat în: scale4/after.jpg\n",
      "PSNR pe imaginea completa: 29.57 dB\n",
      "Loss pe imaginea completa: 0.0142\n"
     ]
    }
   ],
   "source": [
    "# 2 time scale x2\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "\n",
    "def preprocess_full_image(img_path, scale=4):\n",
    "    hr = Image.open(img_path).convert('RGB')\n",
    "    w, h = hr.size\n",
    "    w -= w % scale\n",
    "    h -= h % scale\n",
    "    hr = hr.crop((0, 0, w, h))\n",
    "    lr = hr.resize((w // scale, h // scale), Image.BICUBIC)\n",
    "    return ToTensor()(lr).unsqueeze(0), ToTensor()(hr).unsqueeze(0)\n",
    "\n",
    "def test_model_double_scale2(model_path, test_img_path, output_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = SRNN().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    input_img, target_img = preprocess_full_image(test_img_path, scale=4)\n",
    "    input_img = input_img.to(device)\n",
    "    target_img = target_img.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        out1 = model(input_img)\n",
    "        out2 = model(out1)\n",
    "\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    psnr = calculate_psnr(out2, target_img)\n",
    "    loss = criterion(out2, target_img).item()\n",
    "\n",
    "    to_pil = ToPILImage()\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    to_pil(input_img.squeeze(0).cpu()).save(\"scale4/before.jpg\")\n",
    "    to_pil(out2.squeeze(0).cpu()).save(output_path)\n",
    "    to_pil(target_img.squeeze(0).cpu()).save(\"scale4/ground_truth.jpg\")\n",
    "\n",
    "    print(f\"Output salvat în: {output_path}\")\n",
    "    print(f\"PSNR pe imaginea completa: {psnr:.2f} dB\")\n",
    "    print(f\"Loss pe imaginea completa: {loss:.4f}\")\n",
    "\n",
    "\n",
    "# Exemplu de apel:\n",
    "test_model_double_scale2(\n",
    "    model_path='models2/model5.pth',\n",
    "    test_img_path='dataset/validation/2.jpg',\n",
    "    output_path='scale4/after.jpg'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
